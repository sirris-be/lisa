---
title: Workshop on Hacking LLM Guardrails
short_title: Workshop on Guardrails
layout: event
time:
  from: "13:30"
  to: "17:00"
venue:
  name: Sirris' Leuven office
  address: Gaston Geenslaan 8, 3001 Leuven
remote:
  name: Microsoft Teams
  link: https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY4OThjN2EtZmI0ZC00Mjg3LTk0ZDUtYzU2YmRhNjhjZmE5%40thread.v2/0?context=%7b%22Tid%22%3a%22d4c1d712-e8c2-4fdf-abce-18805891b5b0%22%2c%22Oid%22%3a%22b131c3f0-f2ad-4966-9bd8-2e41122d59c3%22%7d
registration: Required, LISA members receive priority until November 12
requirements:
  - Laptop that can SSH into external machine.
  - Local Python environment and an IDE (both optional).
---

<p>
  In this workshop, participants will get hands-on experience both building and
  breaking AI guardrails.
</p>

<p>
  Working in teams, youâ€™ll design guardrail policies to defend sensitive data
  within a vulnerable AI application, while attempting to bypass those of
  others.
</p>

<p>
  Who will win? The scoreboard will tell, but in the end everyone walks away
  with a deeper grasp of how LLMs can be manipulated and the challenges of
  building robust guardrails.
</p>
