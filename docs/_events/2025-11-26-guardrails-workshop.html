---
title: Workshop on Hacking LLM Guardrails
short_title: Workshop on Guardrails
layout: event
time:
  from: "13:30"
  to: "17:00"
venue:
  name: Sirris' Leuven office
  address: Gaston Geenslaan 8, 3001 Leuven
registration: <a href="https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.eventbrite.be%2Fe%2Fworkshop-on-hacking-llm-guardrails-tickets-1967625848881&data=05%7C02%7Claurent.christophe%40sirris.be%7Cfd14f89808b7482b9a8708de2067fbab%7Cd4c1d712e8c24fdfabce18805891b5b0%7C1%7C0%7C638983828150946725%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=yfoGE64nce9CIK3Z3caNeYhZ2kJGOdMMywgd6kBB%2Fig%3D&reserved=0">Eventbrite</a>
requirements:
  - Laptop that can SSH into external machine.
  - Local Python environment and an IDE (both optional).
---

<p>
  In this workshop, participants will get hands-on experience both building and
  breaking AI guardrails.
</p>

<p>
  Working in teams, youâ€™ll design guardrail policies to defend sensitive data
  within a vulnerable AI application, while attempting to bypass those of
  others.
</p>

<p>
  Who will win? The scoreboard will tell, but in the end everyone walks away
  with a deeper grasp of how LLMs can be manipulated and the challenges of
  building robust guardrails.
</p>
